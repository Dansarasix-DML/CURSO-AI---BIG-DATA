{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKrJ5RO+zUBMdEeii47mEy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# T√©cnicas de Regularizaci√≥n en regresi√≥n lineal\n","\n","La regularizaci√≥n es una t√©cnica clave en Machine Learning que nos ayuda a evitar el sobreajuste y mejorar la generalizaci√≥n de los modelos. Existen tres m√©todos principales de regularizaci√≥n para la regresi√≥n lineal:\n","\n","- Lasso (L1)\n","- Ridge (L2)\n","- Elastic Net (L1 + L2 combinadas)"],"metadata":{"id":"w7RQhL6-v9GV"}},{"cell_type":"markdown","source":["## ¬øQu√© es la regularizaci√≥n y por qu√© es importante?\n","\n","En regresi√≥n lineal, buscamos encontrar los coeficientes\n","Œ≤ que minimicen el error cuadr√°tico medio (MSE):\n","\n","$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n","\n","Sin embargo, cuando tenemos muchas variables predictoras (X), el modelo puede ajustarse demasiado a los datos de entrenamiento (sobreajuste), capturando incluso ruido irrelevante.\n","\n","La regularizaci√≥n a√±ade una penalizaci√≥n a los coeficientes del modelo, forzando a que algunos sean m√°s peque√±os o incluso cero."],"metadata":{"id":"RsoPPQDCxXHS"}},{"cell_type":"markdown","source":["## Ridge Regression (Regularizaci√≥n L2)\n","\n","En Ridge, se agrega una penalizaci√≥n a la suma de los cuadrados de los coeficientes ($\\ell_2$):\n","\n","$$\n","\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n","$$\n","\n","Donde:\n","\n","- Œª ‚Üí Controla la penalizaci√≥n. Si Œª es alto, los coeficientes ser√°n m√°s peque√±os.\n","- $\\sum \\beta_j^2$ ‚Üí La regularizaci√≥n hace que los coeficientes sean peque√±os, pero nunca cero.\n","\n","### Ventajas de Ridge:\n","\n","- Reduce el sobreajuste cuando hay multicolinealidad (variables altamente correlacionadas).\n","- √ötil cuando todas las variables son importantes y queremos reducir su influencia sin eliminarlas."],"metadata":{"id":"vNOerRxoyD5k"}},{"cell_type":"markdown","source":["## Lasso Regression (Regularizaci√≥n L1)\n","\n","Lasso aplica una penalizaci√≥n a la suma del valor absoluto de los coeficientes ($\\ell_1$):\n","\n","$$\n","\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n","$$\n","\n","### Diferencia clave con Ridge:\n","\n","Lasso puede hacer que algunos coeficientes sean exactamente cero, eliminando variables irrelevantes.\n","Esto significa que tambi√©n act√∫a como un m√©todo de selecci√≥n de caracter√≠sticas.\n","\n","### Ventajas de Lasso:\n","\n","- Elimina variables irrelevantes, lo que simplifica el modelo.\n","- √ötil cuando hay muchas variables y queremos seleccionar las m√°s importantes.\n"],"metadata":{"id":"nDOd5gnAxoyA"}},{"cell_type":"markdown","source":["## Elastic Net (combinaci√≥n de L1 y L2)\n","\n","Elastic Net combina Ridge y Lasso, usando una combinaci√≥n de penalizaci√≥n L1 y L2:\n","\n","$$\n","\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2\n","$$\n","\n","### Ventajas de Elastic Net:\n","\n","- Elimina variables irrelevantes (como Lasso), pero mantiene estabilidad en los coeficientes (como Ridge).\n","- √ötil cuando hay muchas variables y algunas est√°n altamente correlacionadas.\n","- Permite ajustar el peso entre L1 y L2 con un hiperpar√°metro Œ±:\n","<pre>\n","            Œ± √ó L1 + (1‚àíŒ±) √ó L2\n","</pre>\n","\n","- Si Œ±=1 ‚Üí Es Lasso puro.\n","- Si Œ±=0 ‚Üí Es Ridge puro.\n","- Si Œ± est√° entre 0 y 1, obtenemos un equilibrio entre ambos."],"metadata":{"id":"9Reu-lckcB2P"}},{"cell_type":"markdown","source":["## Ejemplo pr√°ctico\n","\n","En este ejemplo la regresi√≥n lineal est√°ndar no funciona bien, pero las t√©cnicas de regularizaci√≥n (Ridge, Lasso, Elastic Net) mejoran los resultados. üìä\n","\n","Generaremos 20 variables predictoras $(X_1, X_2, \\dots, X_{20})$, pero solo 3 tienen influencia real en Y.\n","\n","La regresi√≥n lineal sin regularizaci√≥n ajusta todos los coeficientes, incluso los de las variables irrelevantes, lo que provoca sobreajuste y un mayor error.\n","\n","Ridge, Lasso y Elastic Net penalizan coeficientes innecesarios y mejoran la generalizaci√≥n."],"metadata":{"id":"9kscFPckeXfA"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import mean_squared_error\n","\n","SEED = 42\n","TEST_SIZE = 0.2\n","TOTAL_SAMPLES = 200\n","\n","# Generar datos con 20 variables (17 irrelevantes) y ruido\n","np.random.seed(SEED)\n","X = np.random.rand(TOTAL_SAMPLES, 20) * 10\n","y = 4 * X[:, 2] - 2.5 * X[:, 5] + 3 * X[:, 7] + np.random.randn(TOTAL_SAMPLES) * 10\n","\n","# Dividir en entrenamiento y test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED)"],"metadata":{"id":"mgjgWgqlloz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ajustar modelo de regresi√≥n lineal sin regularizaci√≥n\n","lin_reg = LinearRegression()\n","lin_reg.fit(X_train, y_train)\n","y_pred_lr = lin_reg.predict(X_test)\n","\n","# Evaluar rendimiento sin regularizaci√≥n\n","mse_lr = mean_squared_error(y_test, y_pred_lr)\n","\n","mse_lr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3EdsQ46WBYf","executionInfo":{"status":"ok","timestamp":1741181367643,"user_tz":-60,"elapsed":18,"user":{"displayName":"Rafael del Castillo Gomariz","userId":"02979686593806013183"}},"outputId":"4b8cc630-6fc3-4d73-8dc9-e7d8a57638c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128.93058897731407"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Escoger los mejores hiperpar√°metros para Ridge, Lasso y Elastic y construir los modelos\n","\n","# Definir rangos de hiperpar√°metros para cada modelo\n","param_grid_ridge = {'alpha': np.logspace(-3, 2, 10)}\n","param_grid_lasso = {'alpha': np.logspace(-3, 2, 10)}\n","param_grid_elastic = {'alpha': np.logspace(-3, 2, 10), 'l1_ratio': np.linspace(0.1, 0.9, 5)}\n","\n","# GridSearchCV para encontrar mejores hiperpar√°metros\n","ridge_cv = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='neg_mean_squared_error')\n","lasso_cv = GridSearchCV(Lasso(), param_grid_lasso, cv=5, scoring='neg_mean_squared_error')\n","elastic_cv = GridSearchCV(ElasticNet(), param_grid_elastic, cv=5, scoring='neg_mean_squared_error')\n","\n","# Entrenar modelos con los mejores hiperpar√°metros\n","ridge_cv.fit(X_train, y_train)\n","lasso_cv.fit(X_train, y_train)\n","elastic_cv.fit(X_train, y_train)\n","\n","# Mostrar los mejores hiperpar√°metros\n","best_params = {\n","    \"Ridge\": ridge_cv.best_params_,\n","    \"Lasso\": lasso_cv.best_params_,\n","    \"Elastic Net\": elastic_cv.best_params_\n","}\n","print(\"Mejores hiperpar√°metros:\")\n","print(best_params)\n","\n","# Obtener los mejores modelos\n","best_ridge = ridge_cv.best_estimator_\n","best_lasso = lasso_cv.best_estimator_\n","best_elastic = elastic_cv.best_estimator_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yO-sbzMmXEF8","executionInfo":{"status":"ok","timestamp":1741181368584,"user_tz":-60,"elapsed":936,"user":{"displayName":"Rafael del Castillo Gomariz","userId":"02979686593806013183"}},"outputId":"5aa1d3fb-a357-4888-c3e9-0ee1145a507d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mejores hiperpar√°metros:\n","{'Ridge': {'alpha': 27.825594022071257}, 'Lasso': {'alpha': 2.1544346900318843}, 'Elastic Net': {'alpha': 2.1544346900318843, 'l1_ratio': 0.9}}\n"]}]},{"cell_type":"code","source":["MODELS_NAME = [\"Regresi√≥n Lineal\", \"Ridge (L2)\", \"Lasso (L1)\", \"Elastic Net\"]\n","\n","# Generar predicciones con los mejores modelos\n","y_pred_best_ridge = best_ridge.predict(X_test)\n","y_pred_best_lasso = best_lasso.predict(X_test)\n","y_pred_best_elastic = best_elastic.predict(X_test)\n","\n","# Evaluar los modelos optimizados\n","mse_best_ridge = mean_squared_error(y_test, y_pred_best_ridge)\n","mse_best_lasso = mean_squared_error(y_test, y_pred_best_lasso)\n","mse_best_elastic = mean_squared_error(y_test, y_pred_best_elastic)\n","\n","# Obtener el mejor modelo en t√©rminos de error cuadr√°tico medio (MSE)\n","mse_models = [mse_lr, mse_best_ridge, mse_best_lasso, mse_best_elastic]\n","best_model_index = np.argmin(mse_models)\n","best_model_name = MODELS_NAME[best_model_index]\n","best_mse = mse_models[best_model_index]\n","\n","# Mostrar el mejor modelo\n","echo = f\"El mejor modelo es {best_model_name} con un MSE de {best_mse:.2f}\"\n","print(echo)\n","\n","# Comparar los modelos\n","mse_comparison = pd.DataFrame({\n","    \"Modelo\": MODELS_NAME,\n","    \"MSE\": [mse_lr, mse_best_ridge, mse_best_lasso, mse_best_elastic]\n","})\n","\n","mse_comparison"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"FWByiEwKZqQw","executionInfo":{"status":"ok","timestamp":1741181368602,"user_tz":-60,"elapsed":15,"user":{"displayName":"Rafael del Castillo Gomariz","userId":"02979686593806013183"}},"outputId":"7b47a31b-d718-4f8f-91d4-4ab44f7a6db9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["El mejor modelo es Lasso (L1) con un MSE de 120.41\n"]},{"output_type":"execute_result","data":{"text/plain":["             Modelo         MSE\n","0  Regresi√≥n Lineal  128.930589\n","1        Ridge (L2)  127.469233\n","2        Lasso (L1)  120.409488\n","3       Elastic Net  120.417942"],"text/html":["\n","  <div id=\"df-e782c0db-1954-4490-9019-f97eda98dfc1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Modelo</th>\n","      <th>MSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Regresi√≥n Lineal</td>\n","      <td>128.930589</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ridge (L2)</td>\n","      <td>127.469233</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Lasso (L1)</td>\n","      <td>120.409488</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Elastic Net</td>\n","      <td>120.417942</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e782c0db-1954-4490-9019-f97eda98dfc1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e782c0db-1954-4490-9019-f97eda98dfc1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e782c0db-1954-4490-9019-f97eda98dfc1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5699ddfb-30bb-4460-a0cc-31335fd84d21\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5699ddfb-30bb-4460-a0cc-31335fd84d21')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5699ddfb-30bb-4460-a0cc-31335fd84d21 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_deb16cbd-d6b4-415d-9a8b-ace9728f341d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mse_comparison')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_deb16cbd-d6b4-415d-9a8b-ace9728f341d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('mse_comparison');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"mse_comparison","summary":"{\n  \"name\": \"mse_comparison\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Ridge (L2)\",\n          \"Elastic Net\",\n          \"Regresi\\u00f3n Lineal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.534778990655356,\n        \"min\": 120.40948801714235,\n        \"max\": 128.93058897731407,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          127.46923295346967,\n          120.41794231434183,\n          128.93058897731407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Mostrar ecuaciones resultantes sin monomios con coeficientes cero\n","\n","def format_equation(intercept, coefs):\n","    terms = [f\"{coefs[i]:.2f}*X{i+1}\" for i in range(len(coefs)) if coefs[i] != 0]\n","    return f\"Y = {' + '.join(terms)} + {intercept:.2f}\" if terms else f\"Y = {intercept:.2f}\"\n","\n","print(\"Ecuaciones resultantes:\\n\")\n","for model_name, model in zip(MODELS_NAME, [lin_reg, best_ridge, best_lasso, best_elastic]):\n","    equation = format_equation(model.intercept_, model.coef_)\n","    print(f\"{model_name}: {equation}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9AQ25CRbCE4","executionInfo":{"status":"ok","timestamp":1741181714413,"user_tz":-60,"elapsed":56,"user":{"displayName":"Rafael del Castillo Gomariz","userId":"02979686593806013183"}},"outputId":"aec00189-78b5-45ac-bfb8-4d65bed658dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ecuaciones resultantes:\n","\n","Regresi√≥n Lineal: Y = -0.05*X1 + -0.14*X2 + 4.02*X3 + -0.07*X4 + 0.11*X5 + -2.39*X6 + -0.08*X7 + 2.85*X8 + -0.25*X9 + 0.04*X10 + -0.03*X11 + 0.15*X12 + -0.18*X13 + 0.43*X14 + -0.18*X15 + -0.63*X16 + -0.65*X17 + -0.32*X18 + -0.23*X19 + 0.02*X20 + 11.09\n","Ridge (L2): Y = -0.05*X1 + -0.14*X2 + 3.92*X3 + -0.06*X4 + 0.11*X5 + -2.34*X6 + -0.07*X7 + 2.78*X8 + -0.25*X9 + 0.04*X10 + -0.04*X11 + 0.15*X12 + -0.18*X13 + 0.42*X14 + -0.16*X15 + -0.61*X16 + -0.65*X17 + -0.32*X18 + -0.23*X19 + 0.02*X20 + 11.42\n","Lasso (L1): Y = 3.68*X3 + -2.14*X6 + 2.70*X8 + 0.15*X14 + -0.36*X16 + -0.44*X17 + -0.09*X18 + -0.00*X19 + 5.60\n","Elastic Net: Y = 3.60*X3 + -2.11*X6 + 2.65*X8 + -0.02*X9 + 0.17*X14 + -0.37*X16 + -0.46*X17 + -0.11*X18 + -0.03*X19 + 6.49\n"]}]},{"cell_type":"markdown","source":["# ¬øCu√°ndo la regresi√≥n lineal es mejor sin regularizaci√≥n?\n","\n","- Cuando el n√∫mero de muestras (n) es mucho mayor que el n√∫mero de caracter√≠sticas (m).\n","    - Si n‚â´m, el modelo tiene suficiente informaci√≥n para aprender sin sobreajustar.\n","    - No hay riesgo significativo de sobreajuste.\n","    - Regularizar podr√≠a hacer que los coeficientes se reduzcan innecesariamente y perder informaci√≥n √∫til.\n","- Cuando no hay colinealidad entre las variables predictoras.\n","    - Si las variables son independientes, la regresi√≥n lineal est√°ndar encuentra la mejor soluci√≥n sin necesidad de ajustar coeficientes.\n","    - Ridge y Elastic Net ayudan cuando las variables est√°n correlacionadas, pero si no lo est√°n, no se necesita penalizaci√≥n.\n","- Cuando hay pocas variables irrelevantes o ruido bajo.\n","    - Si todas las variables son importantes y no hay muchas caracter√≠sticas irrelevantes, la regularizaci√≥n no es necesaria.\n","    - Lasso eliminar√≠a variables importantes innecesariamente.\n","    - Ridge reducir√≠a coeficientes √∫tiles, haciendo el modelo menos interpretable.\n","- Cuando se necesita interpretar los coeficientes tal como son.\n","    - La regularizaci√≥n modifica los coeficientes, lo que puede dificultar la interpretaci√≥n. Ejemplo:\n","        - Modelos en econom√≠a, medicina o ciencias sociales, donde cada coeficiente tiene un significado real (ej., cu√°nto influye el consumo de az√∫car en el peso de una persona).\n","    - Ridge/Lasso pueden hacer que los coeficientes sean m√°s dif√≠ciles de interpretar.\n","\n","## Resumen\n","\n","| Caso | ¬øSe recomienda regularizaci√≥n? | Motivo |\n","|------|------------------------------|--------|\n","| n >> m **(muchas muestras, pocas variables)** | ‚ùå No | El modelo generaliza bien sin regularizaci√≥n. |\n","| **Variables independientes (sin colinealidad)** | ‚ùå No | No hay problemas de coeficientes inflados. |\n","| **Pocas variables irrelevantes o ruido bajo** | ‚ùå No | Regularizar podr√≠a eliminar o reducir coeficientes √∫tiles. |\n","| **Necesidad de interpretar coeficientes exactos** | ‚ùå No | Regularizaci√≥n puede alterar la interpretaci√≥n. |\n"],"metadata":{"id":"OrbkBgJwmzLj"}}]}